import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from pptx import Presentation
from pptx.util import Inches
import docx
import openpyxl
import re
import io
import dashscope
from dashscope.audio.asr import Transcription
import json
import time
import os
import pathlib  # ğŸŸ¢ æ–°å¢ï¼šç”¨äºå¤„ç† Windows è·¯å¾„

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
st.set_page_config(page_title="è¡Œç ” Copilot Ultimate", layout="wide", page_icon="ğŸš€")
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'Microsoft YaHei', 'PingFang SC']
plt.rcParams['axes.unicode_minus'] = False

if 'ai_config' not in st.session_state: st.session_state['ai_config'] = None
if 'df_cache' not in st.session_state: st.session_state['df_cache'] = None
if 'compliance_results' not in st.session_state: st.session_state['compliance_results'] = []

# ==========================================
# 1. åŸºç¡€è§£æå™¨ (ä¿æŒä¸å˜)
# ==========================================
def clean_text(text):
    if not text: return ""
    return "".join(str(text).split())

def split_segments(full_text):
    segments = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ\n]+', str(full_text))
    return set([clean_text(s) for s in segments if len(clean_text(s)) > 2])

@st.cache_data(show_spinner=False)
def get_docx_text(file):
    try:
        doc = docx.Document(file)
        txt = []
        for p in doc.paragraphs: txt.append(p.text)
        for t in doc.tables:
            for r in t.rows:
                try:
                    for c in r.cells: txt.append(c.text)
                except:
                    try: # æš´åŠ›å®¹é”™
                        for cell in r._element.tc_lst:
                            for p in cell.p_lst:
                                nodes = p.xpath('.//w:t')
                                txt.append("".join([n.text for n in nodes if n.text]))
                    except: pass
        raw = "\n".join(txt)
        return split_segments(raw), raw
    except: return set(), ""

@st.cache_data(show_spinner=False)
def get_pptx_text(file):
    try:
        prs = Presentation(file)
        txt = []
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"): txt.append(shape.text)
                if shape.has_table:
                    for r in shape.table.rows:
                        for c in r.cells: txt.append(c.text)
        raw = "\n".join(txt)
        return split_segments(raw), raw
    except: return set(), ""

@st.cache_data(show_spinner=False)
def get_excel_text(file):
    try:
        wb = openpyxl.load_workbook(file, data_only=True)
        txt = []
        for sheet in wb.sheetnames:
            ws = wb[sheet]
            for row in ws.iter_rows(values_only=True):
                for c in row:
                    if c: txt.append(str(c))
        raw = "\n".join(txt)
        return split_segments(raw), raw
    except: return set(), ""

def dispatch_extractor(file):
    if file.name.endswith('.docx'): return get_docx_text(file)
    elif file.name.endswith('.pptx'): return get_pptx_text(file)
    elif file.name.endswith('.xlsx'): return get_excel_text(file)
    return set(), ""

# ==========================================
# 2. æ¨¡å—ï¼šå…¨æ ¼å¼æ ¸å¯¹ (AI åˆ†æ‰¹å…¨é‡ç‰ˆ)
# ==========================================
def run_ai_batch_check(api_key, context, targets):
    dashscope.api_key = api_key
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è‹›çš„é‡‘èåˆè§„å®¡æ ¸å‘˜ã€‚
    ã€åŸºå‡†äº‹å®ã€‘(æˆªå–):
    {context}
    
    ã€å¾…å®¡æ ¸åˆ—è¡¨ã€‘:
    {json.dumps(targets, ensure_ascii=False)}

    ã€æŒ‡ä»¤ã€‘
    è¯·é€æ¡åˆ¤æ–­ã€å¾…å®¡æ ¸åˆ—è¡¨ã€‘ä¸­çš„å†…å®¹åœ¨ã€åŸºå‡†äº‹å®ã€‘ä¸­æ˜¯å¦æœ‰ä¾æ®ã€‚
    è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ (ä¸è¦ Markdown)ï¼š
    [
        {{"text": "åŸå¥", "result": "âœ…é€šè¿‡/âŒå­˜ç–‘", "reason": "ç®€çŸ­ç†ç”±"}}
    ]
    è‹¥è¯­ä¹‰ä¸€è‡´æˆ–æ•°æ®åŒ¹é…ï¼Œæ ‡è®°é€šè¿‡ï¼›è‹¥æ— ä¸­ç”Ÿæœ‰æˆ–æ•°æ®é”™è¯¯ï¼Œæ ‡è®°å­˜ç–‘ã€‚
    """
    try:
        resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
        content = resp.output.text.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return [{"text": t, "result": "âš ï¸APIé”™è¯¯", "reason": str(e)} for t in targets]

def module_compliance(api_key):
    st.header("ğŸ•µï¸ å…¨æ ¼å¼æ–‡æ¡£æ ¸å¯¹")
    st.markdown("ç­–ç•¥ï¼šä¼˜å…ˆå±•ç¤ºå·®å¼‚ï¼ŒAI åˆ†æ‰¹æ¬¡æ‰«ææ‰€æœ‰æ¡ç›®ï¼Œç¡®ä¿ 0 é—æ¼ã€‚")
    
    c1, c2 = st.columns(2)
    f1 = c1.file_uploader("1. åŸºå‡†æ–‡ä»¶ (Source)", type=['docx','xlsx','pptx'], key="cf1")
    f2 = c2.file_uploader("2. å¾…æµ‹æ–‡ä»¶ (Target)", type=['docx','xlsx','pptx'], key="cf2")
    
    if f1 and f2:
        with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£ç»“æ„..."):
            s1, raw1 = dispatch_extractor(f1)
            s2, raw2 = dispatch_extractor(f2)
            ghosts = list(s2 - s1)
        
        if not ghosts:
            st.success("âœ… å®Œç¾åŒ¹é…ï¼æ— ä»»ä½•å·®å¼‚å†…å®¹ã€‚")
        else:
            st.warning(f"âš ï¸ å…±å‘ç° {len(ghosts)} å¤„åŸå§‹å†…å®¹å·®å¼‚")
            
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´å·®å¼‚æ¸…å•", expanded=True):
                st.dataframe(pd.DataFrame(ghosts, columns=["å¾…å®¡æ ¸å†…å®¹"]), use_container_width=True)

            if st.button("ğŸ§  AI å…¨é‡æ·±åº¦åˆ¤åˆ« (è¦†ç›–æ‰€æœ‰æ¡ç›®)", type="primary", key="btn_ai_full"):
                if not api_key:
                    st.error("è¯·å…ˆè¾“å…¥ API Key")
                    return

                progress_bar = st.progress(0)
                status_text = st.empty()
                all_results = []
                
                BATCH_SIZE = 20
                total_items = len(ghosts)
                safe_context = raw1[:25000]
                
                for i in range(0, total_items, BATCH_SIZE):
                    batch_targets = ghosts[i : i + BATCH_SIZE]
                    status_text.text(f"AI æ­£åœ¨å®¡æ ¸ç¬¬ {i+1} ~ {min(i+BATCH_SIZE, total_items)} æ¡ï¼Œå…± {total_items} æ¡...")
                    
                    batch_res = run_ai_batch_check(api_key, safe_context, batch_targets)
                    all_results.extend(batch_res)
                    progress_bar.progress(min((i + BATCH_SIZE) / total_items, 1.0))
                
                status_text.text("âœ… å®¡æ ¸å®Œæˆï¼")
                st.session_state['compliance_results'] = all_results

            if st.session_state['compliance_results']:
                st.divider()
                st.subheader("ğŸ“‹ AI å®¡æ ¸æŠ¥å‘Š")
                res_df = pd.DataFrame(st.session_state['compliance_results'])
                
                def highlight_row(row):
                    if "âŒ" in str(row['result']) or "âš ï¸" in str(row['result']):
                        return ['background-color: #ffcccc'] * len(row)
                    return [''] * len(row)

                st.dataframe(res_df.style.apply(highlight_row, axis=1), use_container_width=True)

# ==========================================
# 3. æ¨¡å—ï¼šæ™ºèƒ½åˆ¶å›¾ (èŒƒä¾‹ä»¿åˆ¶ç‰ˆ)
# ==========================================
def ai_analyze_chart(api_key, df):
    dashscope.api_key = api_key
    data_sample = df.head(3).to_json(orient='records', force_ascii=False)
    prompt = f"""
    åˆ†ææ•°æ®æ ·ä¾‹: {data_sample}
    ç»™å‡º Matplotlib ç»˜å›¾å»ºè®®ã€‚ä¸¥æ ¼è¿”å› JSON:
    {{
        "chart_type": "dual_axis" æˆ– "bar" æˆ– "line",
        "x_col": "æ—¶é—´æˆ–ç±»åˆ«åˆ—å",
        "y_primary": ["ä¸»è½´åˆ—å"],
        "y_secondary": ["å‰¯è½´åˆ—å"],
        "title": "å»ºè®®æ ‡é¢˜"
    }}
    """
    try:
        resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
        return json.loads(resp.output.text.replace("```json","").replace("```","").strip())
    except: return None

def module_smart_chart_ref(api_key):
    st.header("ğŸ“Š æ™ºèƒ½åˆ¶å›¾ (èŒƒä¾‹ä»¿åˆ¶)")
    st.markdown("å·¥ä½œæµï¼šä¸Šä¼ å‚è€ƒå›¾ -> AIåˆ†ææ•°æ® -> è°ƒæ•´æ ·å¼ä»¥åŒ¹é…å‚è€ƒå›¾ -> å¯¼å‡ºã€‚")
    
    c1, c2 = st.columns(2)
    ref_img = c1.file_uploader("1. å‚è€ƒèŒƒä¾‹ (æˆªå›¾)", type=['png','jpg'], key="ci_1")
    data_file = c2.file_uploader("2. æ•°æ® Excel", type=['xlsx'], key="ci_2")
    
    if ref_img: c1.image(ref_img, caption="ç›®æ ‡æ ·å¼", use_column_width=True)
    
    if data_file and api_key:
        df = pd.read_excel(data_file)
        st.session_state['df_cache'] = df
        
        if st.button("ğŸ¤– AI åˆ†ææ•°æ®ç»“æ„", key="btn_chart_ai"):
            with st.spinner("AI æ­£åœ¨è§£ææ•°æ®ç»´åº¦..."):
                cfg = ai_analyze_chart(api_key, df)
                if cfg:
                    st.session_state['ai_config'] = cfg
                    st.success("åˆ†æå®Œæˆï¼Œè¯·ä¸‹æ–¹è°ƒæ•´ã€‚")
                else: st.error("AI åˆ†æå¤±è´¥")

    if st.session_state['ai_config']:
        cfg = st.session_state['ai_config']
        df = st.session_state['df_cache']
        cols = df.columns.tolist()
        
        st.divider()
        st.subheader("ğŸ¨ æ ·å¼å¯¹é½")
        cc1, cc2 = st.columns([1, 2])
        
        with cc1:
            c_type = st.selectbox("å›¾è¡¨ç±»å‹", ["dual_axis", "bar", "line"], index=["dual_axis", "bar", "line"].index(cfg.get('chart_type','bar')), key="s_type")
            c_x = st.selectbox("Xè½´", cols, index=cols.index(cfg.get('x_col')) if cfg.get('x_col') in cols else 0, key="s_x")
            
            def_y1 = [c for c in cfg.get('y_primary',[]) if c in cols]
            c_y1 = st.multiselect("å·¦è½´æ•°æ®", cols, default=def_y1 if def_y1 else [cols[1]], key="s_y1")
            
            def_y2 = [c for c in cfg.get('y_secondary',[]) if c in cols]
            c_y2 = st.multiselect("å³è½´æ•°æ®", cols, default=def_y2, key="s_y2")
            
            st.markdown("---")
            col1 = st.color_picker("ä¸»è‰² (å¸å–å‚è€ƒå›¾)", "#C00000", key="cp1")
            col2 = st.color_picker("å‰¯è‰²", "#FFC000", key="cp2")
            f_size = st.slider("å­—å·", 8, 20, 10, key="fs")
            c_title = st.text_input("æ ‡é¢˜", value=cfg.get('title','Chart'), key="st")

        with cc2:
            plt.rcParams.update({'font.size': f_size})
            fig, ax1 = plt.subplots(figsize=(8, 4.5))
            
            if c_type == "dual_axis":
                ax1.bar(df[c_x], df[c_y1[0]], color=col1, alpha=0.8, label=c_y1[0])
                ax1.set_ylabel(c_y1[0], color=col1, fontweight='bold')
                if c_y2:
                    ax2 = ax1.twinx()
                    ax2.plot(df[c_x], df[c_y2[0]], color=col2, marker='o', linewidth=2, label=c_y2[0])
                    ax2.grid(False)
            elif c_type == "bar":
                for i,c in enumerate(c_y1): ax1.bar(df[c_x], df[c], color=col1 if i==0 else None, alpha=0.8)
            elif c_type == "line":
                for i,c in enumerate(c_y1): ax1.plot(df[c_x], df[c], color=col2 if i==0 else None, marker='o')
            
            ax1.set_title(c_title, pad=15, fontweight='bold')
            ax1.grid(True, linestyle='--', alpha=0.5)
            st.pyplot(fig)
            
            img = io.BytesIO()
            plt.savefig(img, format='png', dpi=300, bbox_inches='tight')
            img.seek(0)
            
            ppt = io.BytesIO()
            prs = Presentation()
            slide = prs.slides.add_slide(prs.slide_layouts[6])
            slide.shapes.add_picture(img, Inches(0.5), Inches(0.5), width=Inches(9))
            prs.save(ppt)
            ppt.seek(0)
            img.seek(0)
            
            d1, d2 = st.columns(2)
            d1.download_button("ğŸ“¥ ä¸‹è½½ PNG", img, "chart.png", "image/png", key="dl_1")
            d2.download_button("ğŸ“¥ ä¸‹è½½ PPT", ppt, "chart.pptx", key="dl_2")

# ==========================================
# 4. æ¨¡å—ï¼šæ™ºèƒ½ä¼šè®®çºªè¦ (ä¿®å¤ Windows è·¯å¾„ & å´©æºƒé—®é¢˜)
# ==========================================

def module_meeting_real(api_key):
    st.header("ğŸ™ï¸ æ™ºèƒ½ä¼šè®®çºªè¦ (Paraformer å¼•æ“)")
    st.markdown("ä¸Šä¼ å½•éŸ³ -> **é˜¿é‡Œäº‘ Paraformer è½¬å†™** -> ç”Ÿæˆ **Q&A ç»“æ„åŒ–** çºªè¦ã€‚")
    st.caption("âš ï¸ æ³¨æ„ï¼šéœ€è¦æ¶ˆè€— API é¢åº¦ï¼Œæ”¯æŒé•¿éŸ³é¢‘å¼‚æ­¥å¤„ç†ã€‚å»ºè®®ä½¿ç”¨ MP3 æ ¼å¼ã€‚")
    
    f = st.file_uploader("ä¸Šä¼ å½•éŸ³ (å»ºè®® MP3/WAV)", type=['mp3','wav','m4a'], key="mf_real")
    
    if f and st.button("å¼€å§‹çœŸå®è½¬å†™ä¸åˆ†æ", key="btn_meet_real"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥ API Key")
            return

        dashscope.api_key = api_key
        
        # 1. ä¿å­˜ä¸´æ—¶æ–‡ä»¶ (å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„)
        temp_filename = f"temp_meeting.{f.name.split('.')[-1]}"
        with open(temp_filename, "wb") as temp_f:
            temp_f.write(f.getbuffer())
        
        # è·å–ç»å¯¹è·¯å¾„ï¼Œå¹¶è½¬ä¸º Windows å…¼å®¹çš„ URL æ ¼å¼
        abs_path = pathlib.Path(temp_filename).resolve()
        file_url = abs_path.as_uri() # è‡ªåŠ¨å¤„ç†ä¸º file:///C:/... æ ¼å¼ï¼Œé˜²æ­¢ DECODE_ERROR
        
        st.info(f"ğŸ’¾ æ–‡ä»¶å·²ç¼“å­˜ï¼Œæ­£åœ¨ä¸Šä¼ è‡³è¯­éŸ³å¼•æ“ (Size: {f.size/1024/1024:.2f}MB)...")
        
        try:
            # 2. è°ƒç”¨ DashScope ASR
            # ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ URL è¿›è¡Œè°ƒç”¨
            task_response = Transcription.async_call(
                model='paraformer-v1',
                file_urls=[file_url] 
            )
            
            transcribe_state = st.empty()
            progress_bar = st.progress(0)
            transcribe_state.text("â³ æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (äº‘ç«¯å¤„ç†ä¸­)...")
            
            # 3. è½®è¯¢ç­‰å¾…
            task_id = task_response.output.task_id
            status = 'RUNNING'
            start_time = time.time()
            
            while status == 'RUNNING' or status == 'QUEUED':
                time.sleep(3) # é¿å…é¢‘ç¹è¯·æ±‚
                wait_response = Transcription.wait(task=task_id)
                status = wait_response.output.task_status
                
                # ç®€å•æ¨¡æ‹Ÿè¿›åº¦æ¡ (å› ä¸ºä¸çŸ¥é“å…·ä½“å¤šä¹…ï¼Œå‡è£…åœ¨è·‘)
                elapsed = time.time() - start_time
                progress = min(elapsed / 60.0, 0.9) # å‡è®¾1åˆ†é’Ÿå†…èƒ½è·‘å®Œå¤§éƒ¨åˆ†
                progress_bar.progress(progress)

                if status == 'SUCCEEDED':
                    progress_bar.progress(1.0)
                    # 4. è·å–è½¬å†™æ–‡æœ¬
                    results = wait_response.output.results
                    full_transcript = ""
                    if results:
                        for sentence in results[0]['sentences']:
                            speaker = f"è¯´è¯äºº{sentence.get('speaker_id', '?')}"
                            text = sentence['text']
                            full_transcript += f"{speaker}: {text}\n"
                    
                    transcribe_state.success("âœ… è¯­éŸ³è¯†åˆ«å®Œæˆï¼")
                    with st.expander("ğŸ“„ æŸ¥çœ‹è¯†åˆ«åŸæ–‡"):
                        st.text_area("Transcript", full_transcript, height=200)
                    
                    # 5. è°ƒç”¨ LLM æ•´ç†
                    st.info("ğŸ§  AI æ­£åœ¨æ•´ç† Q&A ç»“æ„...")
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä¸ªè¡Œç ”åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®å½•éŸ³è½¬å†™æ–‡æœ¬ï¼Œæ•´ç†ä¸€ä»½è§„èŒƒçš„ä¼šè®®çºªè¦ã€‚
                    
                    ã€è¦æ±‚ã€‘
                    1. ã€æ ¸å¿ƒè§‚ç‚¹ã€‘ï¼šæ€»ç»“ä¼šè®®çš„æ ¸å¿ƒä¸šç»©ã€æŒ‡å¼•ç­‰å…³é”®ä¿¡æ¯ (Bullet points)ã€‚
                    2. ã€Q&Aç¯èŠ‚ã€‘ï¼šå¿…é¡»ä¸¥æ ¼åŒºåˆ†æé—®è€…å’Œå›ç­”è€…ï¼ŒæŒ‰ "Q: [é—®é¢˜] \n A: [å›ç­”]" æ ¼å¼æ•´ç†ã€‚
                    3. å»é™¤å£è¯­åºŸè¯ï¼Œé€»è¾‘é€šé¡ºã€‚
                    
                    ã€è½¬å†™æ–‡æœ¬ã€‘ï¼š
                    {full_transcript[:20000]} 
                    """
                    
                    try:
                        llm_resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
                        st.divider()
                        st.markdown("### ğŸ“ æ™ºèƒ½ä¼šè®®çºªè¦")
                        st.markdown(llm_resp.output.text)
                        st.download_button("ä¸‹è½½çºªè¦ TXT", llm_resp.output.text, "minutes.txt")
                    except Exception as e:
                        st.error(f"AI æ•´ç†å¤±è´¥: {e}")
                    
                    break
                    
                elif status == 'FAILED':
                    st.error(f"è¯­éŸ³è¯†åˆ«ä»»åŠ¡å¤±è´¥: {wait_response.output.message}")
                    if "DECODE_ERROR" in str(wait_response.output.message):
                        st.warning("ğŸ’¡ æç¤ºï¼šDECODE_ERROR é€šå¸¸æ„å‘³ç€éŸ³é¢‘æ ¼å¼ä¸å…¼å®¹ã€‚è¯·å°è¯•å°† m4a è½¬æ¢ä¸º mp3 æ ¼å¼åå†ä¸Šä¼ ã€‚")
                    break
                    
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (æ”¾åœ¨ finally é‡Œé˜²æ­¢æ®‹ç•™)
            if os.path.exists(temp_filename): 
                try: os.remove(temp_filename)
                except: pass

# ==========================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==========================================
with st.sidebar:
    st.title("ğŸš€ è¡Œç ” Copilot")
    api_key = st.text_input("ğŸ”‘ API Key", type="password", key="mk")
    st.divider()
    mode = st.radio("åŠŸèƒ½å¯¼èˆª", ["ğŸ•µï¸ å…¨æ ¼å¼æ ¸å¯¹", "ğŸ“Š æ™ºèƒ½åˆ¶å›¾", "ğŸ™ï¸ ä¼šè®®çºªè¦"], key="nav")

if mode == "ğŸ•µï¸ å…¨æ ¼å¼æ ¸å¯¹": module_compliance(api_key)
elif mode == "ğŸ“Š æ™ºèƒ½åˆ¶å›¾": module_smart_chart_ref(api_key)
elif mode == "ğŸ™ï¸ ä¼šè®®çºªè¦": module_meeting_real(api_key)