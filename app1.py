import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from pptx import Presentation
from pptx.util import Inches
import docx
import openpyxl
import re
import io
import dashscope
import json
import time

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
st.set_page_config(page_title="è¡Œç ” Copilot Ultimate", layout="wide", page_icon="ğŸš€")

# è®¾ç½®ä¸­æ–‡å­—ä½“ (å…¼å®¹ Windows/Linux)
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'Microsoft YaHei', 'PingFang SC']
plt.rcParams['axes.unicode_minus'] = False

# åˆå§‹åŒ– Session State
if 'ai_config' not in st.session_state: st.session_state['ai_config'] = None
if 'df_cache' not in st.session_state: st.session_state['df_cache'] = None
if 'compliance_results' not in st.session_state: st.session_state['compliance_results'] = []

# ==========================================
# 1. æ ¸å¿ƒè§£æå™¨ (é«˜å®¹é”™ç‰ˆ)
# ==========================================

def clean_text(text):
    """æ¸…æ´—ï¼šå»é‡ç©ºç™½ç¬¦"""
    if not text: return ""
    return "".join(str(text).split())

def split_segments(full_text):
    """åˆ†è¯ï¼šæŒ‰æ ‡ç‚¹åˆ‡åˆ†ï¼Œä¿ç•™é•¿å¥"""
    segments = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ\n]+', str(full_text))
    return set([clean_text(s) for s in segments if len(clean_text(s)) > 2])

@st.cache_data(show_spinner=False)
def get_docx_text(file):
    """è§£æ Word (å«å¤æ‚è¡¨æ ¼ä¿®å¤)"""
    try:
        doc = docx.Document(file)
    except: return set(), ""
    
    txt = []
    # æ®µè½
    for p in doc.paragraphs: txt.append(p.text)
    # è¡¨æ ¼ (æš´åŠ›å®¹é”™è¯»å–)
    for t in doc.tables:
        for r in t.rows:
            try:
                for c in r.cells: txt.append(c.text)
            except: 
                # XML æš´åŠ›è¯»å–å…œåº•
                try:
                    for cell in r._element.tc_lst:
                        for p in cell.p_lst:
                            nodes = p.xpath('.//w:t')
                            txt.append("".join([n.text for n in nodes if n.text]))
                except: pass
    raw = "\n".join(txt)
    return split_segments(raw), raw

@st.cache_data(show_spinner=False)
def get_pptx_text(file):
    """è§£æ PPT"""
    try:
        prs = Presentation(file)
    except: return set(), ""
    txt = []
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"): txt.append(shape.text)
            if shape.has_table:
                for r in shape.table.rows:
                    for c in r.cells: txt.append(c.text)
    raw = "\n".join(txt)
    return split_segments(raw), raw

@st.cache_data(show_spinner=False)
def get_excel_text(file):
    """è§£æ Excel"""
    try:
        wb = openpyxl.load_workbook(file, data_only=True)
    except: return set(), ""
    txt = []
    for sheet in wb.sheetnames:
        ws = wb[sheet]
        for row in ws.iter_rows(values_only=True):
            for c in row:
                if c: txt.append(str(c))
    raw = "\n".join(txt)
    return split_segments(raw), raw

def dispatch_extractor(file):
    if file.name.endswith('.docx'): return get_docx_text(file)
    elif file.name.endswith('.pptx'): return get_pptx_text(file)
    elif file.name.endswith('.xlsx'): return get_excel_text(file)
    return set(), ""

# ==========================================
# 2. æ¨¡å—ï¼šå…¨æ ¼å¼æ ¸å¯¹ (åˆ†æ‰¹æ¬¡å…¨è¦†ç›–ç‰ˆ)
# ==========================================

def run_ai_batch_check(api_key, context, targets):
    """
    AI æ‰¹æ¬¡å¤„ç†å‡½æ•°ï¼šç”±äº LLM è¾“å‡ºé•¿åº¦æœ‰é™ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå·®å¼‚é¡¹åˆ†æ‰¹å‘é€
    """
    dashscope.api_key = api_key
    # æ„é€  Promptï¼šè¦æ±‚ AI è¿”å› JSON æ ¼å¼
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è‹›çš„é‡‘èåˆè§„å®¡æ ¸å‘˜ã€‚
    ã€åŸºå‡†äº‹å®ã€‘(æˆªå–éƒ¨åˆ†):
    {context}
    
    ã€å¾…å®¡æ ¸åˆ—è¡¨ã€‘:
    {json.dumps(targets, ensure_ascii=False)}

    ã€æŒ‡ä»¤ã€‘
    è¯·é€æ¡åˆ¤æ–­ã€å¾…å®¡æ ¸åˆ—è¡¨ã€‘ä¸­çš„å†…å®¹åœ¨ã€åŸºå‡†äº‹å®ã€‘ä¸­æ˜¯å¦æœ‰ä¾æ®ã€‚
    ä¸è¦é—æ¼ä»»ä½•ä¸€æ¡ã€‚
    è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ (ä¸è¦ Markdown)ï¼š
    [
        {{"text": "åŸå¥", "result": "âœ…é€šè¿‡/âŒå­˜ç–‘", "reason": "ç®€çŸ­ç†ç”±"}}
    ]
    è‹¥è¯­ä¹‰ä¸€è‡´æˆ–æ•°æ®åŒ¹é…ï¼Œæ ‡è®°é€šè¿‡ï¼›è‹¥æ— ä¸­ç”Ÿæœ‰æˆ–æ•°æ®é”™è¯¯ï¼Œæ ‡è®°å­˜ç–‘ã€‚
    """
    try:
        # ä½¿ç”¨ turbo æ¨¡å‹é€Ÿåº¦è¾ƒå¿«ï¼Œå¦‚æœéœ€è¦æ›´é«˜ç²¾åº¦å¯æ¢ qwen-plus
        resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
        content = resp.output.text.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        return [{"text": t, "result": "âš ï¸APIé”™è¯¯", "reason": str(e)} for t in targets]

def module_compliance(api_key):
    st.header("ğŸ•µï¸ å…¨æ ¼å¼æ–‡æ¡£æ ¸å¯¹ (å…¨é‡è¦†ç›–ç‰ˆ)")
    st.markdown("æ”¯æŒ Word/Excel/PPT äº’æŸ¥ã€‚**ç­–ç•¥ï¼š** ä¼˜å…ˆå±•ç¤ºå®Œæ•´å·®å¼‚ï¼ŒAI åˆ†æ‰¹æ¬¡æ‰«ææ‰€æœ‰æ¡ç›®ï¼Œç¡®ä¿ 0 é—æ¼ã€‚")
    
    c1, c2 = st.columns(2)
    f1 = c1.file_uploader("1. åŸºå‡†æ–‡ä»¶ (Source)", type=['docx','xlsx','pptx'], key="cf1")
    f2 = c2.file_uploader("2. å¾…æµ‹æ–‡ä»¶ (Target)", type=['docx','xlsx','pptx'], key="cf2")
    
    if f1 and f2:
        with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£ç»“æ„..."):
            s1, raw1 = dispatch_extractor(f1)
            s2, raw2 = dispatch_extractor(f2)
            ghosts = list(s2 - s1)
        
        # --- ä¼˜åŒ–ç‚¹ï¼šAI ä»‹å…¥å‰ï¼Œå…ˆå±•ç¤ºå®Œæ•´å·®å¼‚ ---
        if not ghosts:
            st.success("âœ… å®Œç¾åŒ¹é…ï¼æ— ä»»ä½•å·®å¼‚å†…å®¹ã€‚")
        else:
            st.warning(f"âš ï¸ å…±å‘ç° {len(ghosts)} å¤„åŸå§‹å†…å®¹å·®å¼‚")
            
            # å±•ç¤ºåŸç”Ÿå·®å¼‚åˆ—è¡¨
            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´å·®å¼‚æ¸…å• (ç‚¹å‡»å±•å¼€)", expanded=True):
                st.dataframe(pd.DataFrame(ghosts, columns=["å¾…å®¡æ ¸å†…å®¹"]), use_container_width=True)

            # --- AI å…¨é‡æ‰«æ ---
            if st.button("ğŸ§  AI å…¨é‡æ·±åº¦åˆ¤åˆ« (è¦†ç›–æ‰€æœ‰æ¡ç›®)", type="primary", key="btn_ai_full"):
                if not api_key:
                    st.error("è¯·å…ˆè¾“å…¥ API Key")
                    return

                # åˆå§‹åŒ–è¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                all_results = []
                
                # åˆ†æ‰¹ç­–ç•¥ï¼šæ¯æ¬¡å¤„ç† 20 æ¡ï¼Œé˜²æ­¢ Token æº¢å‡º
                BATCH_SIZE = 20
                total_items = len(ghosts)
                
                # æˆªå–åŸºå‡†ä¸Šä¸‹æ–‡ (ä¿ç•™å‰ 2.5ä¸‡å­—ï¼Œé€šå¸¸æ¶µç›–æ ¸å¿ƒå†…å®¹)
                # è¿™é‡Œçš„ç­–ç•¥æ˜¯ï¼šä¿è¯ä¸Šä¸‹æ–‡è¶³å¤Ÿé•¿ï¼Œè€Œä¸æ˜¯ä¸ºäº†é€Ÿåº¦å»è¿‡åº¦è£å‰ª
                safe_context = raw1[:25000]
                
                for i in range(0, total_items, BATCH_SIZE):
                    batch_targets = ghosts[i : i + BATCH_SIZE]
                    status_text.text(f"AI æ­£åœ¨å®¡æ ¸ç¬¬ {i+1} ~ {min(i+BATCH_SIZE, total_items)} æ¡ï¼Œå…± {total_items} æ¡...")
                    
                    # è°ƒç”¨ AI
                    batch_res = run_ai_batch_check(api_key, safe_context, batch_targets)
                    all_results.extend(batch_res)
                    
                    # æ›´æ–°è¿›åº¦
                    progress_bar.progress(min((i + BATCH_SIZE) / total_items, 1.0))
                
                status_text.text("âœ… å®¡æ ¸å®Œæˆï¼")
                st.session_state['compliance_results'] = all_results

            # --- å±•ç¤º AI ç»“æœ ---
            if st.session_state['compliance_results']:
                st.divider()
                st.subheader("ğŸ“‹ AI å®¡æ ¸æŠ¥å‘Š")
                
                res_df = pd.DataFrame(st.session_state['compliance_results'])
                
                # é«˜äº®æ˜¾ç¤ºå­˜ç–‘é¡¹
                def highlight_row(row):
                    if "âŒ" in str(row['result']) or "âš ï¸" in str(row['result']):
                        return ['background-color: #ffcccc'] * len(row)
                    return [''] * len(row)

                st.dataframe(
                    res_df.style.apply(highlight_row, axis=1), 
                    use_container_width=True,
                    column_config={
                        "text": "åŸå¥",
                        "result": "åˆ¤å®šç»“æœ",
                        "reason": "AI ç†ç”±"
                    }
                )
                
                # ç»Ÿè®¡æ¦‚è§ˆ
                fail_count = len([x for x in st.session_state['compliance_results'] if "âŒ" in x['result']])
                if fail_count > 0:
                    st.error(f"å‘ç° {fail_count} ä¸ªé«˜é£é™©å­˜ç–‘é¡¹ï¼Œè¯·é‡ç‚¹æ ¸å¯¹ï¼")
                else:
                    st.success("æ‰€æœ‰å·®å¼‚é¡¹å‡å·²é€šè¿‡ AI è¯­ä¹‰åˆè§„æ€§æ£€æŸ¥ã€‚")

# ==========================================
# 3. æ¨¡å—ï¼šæ™ºèƒ½åˆ¶å›¾ (èŒƒä¾‹ä»¿åˆ¶ç‰ˆ)
# ==========================================

def ai_analyze_chart(api_key, df):
    """AI å›¾è¡¨é…ç½®åˆ†æ"""
    dashscope.api_key = api_key
    data_sample = df.head(3).to_json(orient='records', force_ascii=False)
    prompt = f"""
    åˆ†ææ•°æ®æ ·ä¾‹: {data_sample}
    ç»™å‡º Matplotlib ç»˜å›¾å»ºè®®ã€‚ä¸¥æ ¼è¿”å› JSON:
    {{
        "chart_type": "dual_axis" æˆ– "bar" æˆ– "line",
        "x_col": "æ—¶é—´æˆ–ç±»åˆ«åˆ—å",
        "y_primary": ["ä¸»è½´åˆ—å"],
        "y_secondary": ["å‰¯è½´åˆ—å"],
        "title": "å»ºè®®æ ‡é¢˜"
    }}
    """
    try:
        resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
        return json.loads(resp.output.text.replace("```json","").replace("```","").strip())
    except: return None

def module_smart_chart_ref(api_key):
    st.header("ğŸ“Š æ™ºèƒ½åˆ¶å›¾ (èŒƒä¾‹ä»¿åˆ¶)")
    st.markdown("å·¥ä½œæµï¼šä¸Šä¼ å‚è€ƒå›¾ -> AIåˆ†ææ•°æ® -> è°ƒæ•´æ ·å¼ä»¥åŒ¹é…å‚è€ƒå›¾ -> å¯¼å‡ºã€‚")
    
    c1, c2 = st.columns(2)
    ref_img = c1.file_uploader("1. å‚è€ƒèŒƒä¾‹ (æˆªå›¾)", type=['png','jpg'], key="ci_1")
    data_file = c2.file_uploader("2. æ•°æ® Excel", type=['xlsx'], key="ci_2")
    
    if ref_img: c1.image(ref_img, caption="ç›®æ ‡æ ·å¼", use_column_width=True)
    
    if data_file and api_key:
        df = pd.read_excel(data_file)
        st.session_state['df_cache'] = df
        
        if st.button("ğŸ¤– AI åˆ†ææ•°æ®ç»“æ„", key="btn_chart_ai"):
            with st.spinner("AI æ­£åœ¨è§£ææ•°æ®ç»´åº¦..."):
                cfg = ai_analyze_chart(api_key, df)
                if cfg:
                    st.session_state['ai_config'] = cfg
                    st.success("åˆ†æå®Œæˆï¼Œè¯·ä¸‹æ–¹è°ƒæ•´ã€‚")
                else: st.error("AI åˆ†æå¤±è´¥")

    if st.session_state['ai_config']:
        cfg = st.session_state['ai_config']
        df = st.session_state['df_cache']
        cols = df.columns.tolist()
        
        st.divider()
        st.subheader("ğŸ¨ æ ·å¼å¯¹é½")
        cc1, cc2 = st.columns([1, 2])
        
        with cc1:
            # äº¤äº’å¾®è°ƒåŒº
            c_type = st.selectbox("å›¾è¡¨ç±»å‹", ["dual_axis", "bar", "line"], index=["dual_axis", "bar", "line"].index(cfg.get('chart_type','bar')), key="s_type")
            c_x = st.selectbox("Xè½´", cols, index=cols.index(cfg.get('x_col')) if cfg.get('x_col') in cols else 0, key="s_x")
            
            def_y1 = [c for c in cfg.get('y_primary',[]) if c in cols]
            c_y1 = st.multiselect("å·¦è½´æ•°æ®", cols, default=def_y1 if def_y1 else [cols[1]], key="s_y1")
            
            def_y2 = [c for c in cfg.get('y_secondary',[]) if c in cols]
            c_y2 = st.multiselect("å³è½´æ•°æ®", cols, default=def_y2, key="s_y2")
            
            st.markdown("---")
            col1 = st.color_picker("ä¸»è‰² (å¸å–å‚è€ƒå›¾)", "#C00000", key="cp1")
            col2 = st.color_picker("å‰¯è‰²", "#FFC000", key="cp2")
            f_size = st.slider("å­—å·", 8, 20, 10, key="fs")
            c_title = st.text_input("æ ‡é¢˜", value=cfg.get('title','Chart'), key="st")

        with cc2:
            # ç»˜å›¾é€»è¾‘
            plt.rcParams.update({'font.size': f_size})
            fig, ax1 = plt.subplots(figsize=(8, 4.5))
            
            if c_type == "dual_axis":
                ax1.bar(df[c_x], df[c_y1[0]], color=col1, alpha=0.8, label=c_y1[0])
                ax1.set_ylabel(c_y1[0], color=col1, fontweight='bold')
                if c_y2:
                    ax2 = ax1.twinx()
                    ax2.plot(df[c_x], df[c_y2[0]], color=col2, marker='o', linewidth=2, label=c_y2[0])
                    ax2.grid(False)
            elif c_type == "bar":
                for i,c in enumerate(c_y1): ax1.bar(df[c_x], df[c], color=col1 if i==0 else None, alpha=0.8)
            elif c_type == "line":
                for i,c in enumerate(c_y1): ax1.plot(df[c_x], df[c], color=col2 if i==0 else None, marker='o')
            
            ax1.set_title(c_title, pad=15, fontweight='bold')
            ax1.grid(True, linestyle='--', alpha=0.5)
            st.pyplot(fig)
            
            # å¯¼å‡ºé€»è¾‘
            img = io.BytesIO()
            plt.savefig(img, format='png', dpi=300, bbox_inches='tight')
            img.seek(0)
            
            ppt = io.BytesIO()
            prs = Presentation()
            slide = prs.slides.add_slide(prs.slide_layouts[6])
            slide.shapes.add_picture(img, Inches(0.5), Inches(0.5), width=Inches(9))
            prs.save(ppt)
            ppt.seek(0)
            img.seek(0)
            
            d1, d2 = st.columns(2)
            d1.download_button("ğŸ“¥ ä¸‹è½½ PNG", img, "chart.png", "image/png", key="dl_1")
            d2.download_button("ğŸ“¥ ä¸‹è½½ PPT", ppt, "chart.pptx", key="dl_2")

# ==========================================
# 4. æ¨¡å—ï¼šæ™ºèƒ½ä¼šè®®çºªè¦ (Q&Aç‰ˆ)
# ==========================================
def module_meeting(api_key):
    st.header("ğŸ™ï¸ æ™ºèƒ½ä¼šè®®çºªè¦")
    st.markdown("ä¸Šä¼ å½•éŸ³ -> è‡ªåŠ¨è½¬å†™ -> ç”Ÿæˆ **Q&A ç»“æ„åŒ–** çºªè¦ã€‚")
    
    f = st.file_uploader("ä¸Šä¼ å½•éŸ³", type=['mp3','wav','m4a'], key="mf")
    
    if f and st.button("å¼€å§‹åˆ†æ", key="btn_meet"):
        if not api_key: st.error("No API Key"); return
        
        st.info("ğŸ”„ æ¨¡æ‹Ÿ ASR è½¬å†™ä¸­... (çœŸå®ç¯å¢ƒéœ€å¯¹æ¥é•¿éŸ³é¢‘æ¥å£)")
        time.sleep(1.5)
        mock_text = """
        ç‹æ€»ï¼šQ1è¥æ”¶100äº¿ï¼Œå¢20%ã€‚åˆ†æå¸ˆAï¼šæ¯›åˆ©ä¸ºä½•é™ï¼Ÿç‹æ€»ï¼šé“œä»·æ¶¨äº†ã€‚
        åˆ†æå¸ˆBï¼šæœªæ¥æŒ‡å¼•ï¼Ÿç‹æ€»ï¼šä¸‹åŠå¹´å›å‡è‡³30%ã€‚
        """
        st.text_area("è¯†åˆ«ç»“æœ", mock_text)
        
        dashscope.api_key = api_key
        prompt = f"å°†ä»¥ä¸‹æ–‡æœ¬æ•´ç†ä¸ºè¡Œç ”ä¼šè®®çºªè¦ã€‚è¦æ±‚ï¼š1.æ ¸å¿ƒè§‚ç‚¹ã€‚2.Q&Aç¯èŠ‚ä¸¥æ ¼æŒ‰'Q: A:'æ ¼å¼ã€‚æ–‡æœ¬ï¼š{mock_text}"
        
        try:
            resp = dashscope.Generation.call(model='qwen-turbo', prompt=prompt)
            st.markdown("### ğŸ“ çºªè¦é¢„è§ˆ")
            st.markdown(resp.output.text)
            st.download_button("ä¸‹è½½ TXT", resp.output.text, "minutes.txt", key="dl_txt")
        except: pass

# ==========================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==========================================
with st.sidebar:
    st.title("ğŸš€ è¡Œç ” Copilot")
    api_key = st.text_input("ğŸ”‘ API Key", type="password", key="mk")
    st.divider()
    mode = st.radio("åŠŸèƒ½å¯¼èˆª", ["ğŸ•µï¸ å…¨æ ¼å¼æ ¸å¯¹", "ğŸ“Š æ™ºèƒ½åˆ¶å›¾", "ğŸ™ï¸ ä¼šè®®çºªè¦"], key="nav")

if mode == "ğŸ•µï¸ å…¨æ ¼å¼æ ¸å¯¹": module_compliance(api_key)
elif mode == "ğŸ“Š æ™ºèƒ½åˆ¶å›¾": module_smart_chart_ref(api_key)
elif mode == "ğŸ™ï¸ ä¼šè®®çºªè¦": module_meeting(api_key)